{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import psycopg2\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from itertools import chain \n",
    "from IPython.display import Image\n",
    "import math\n",
    "import time\n",
    "import logging \n",
    "import requests\n",
    "import json\n",
    "print(\"Imported all packages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GoogleNews...\n",
      "Loaded GoogleNews!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading GoogleNews...\")\n",
    "from gensim import models\n",
    "w = models.KeyedVectors.load_word2vec_format(r\"F:\\Pretrained Models\\GoogleNews-vectors-negative300.bin.gz\", binary=True, limit=2100000)\n",
    "print(\"Loaded GoogleNews!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(array,avoidwords):\n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',str(array))  #Remove Numbers\n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text) # Remove nums\n",
    "    text = re.sub(r'\\s+',' ',text)  #Remove extra space\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]+\",' ',text)  #Remove special characters\n",
    "    text = text.lower()  #Lower case all\n",
    "    text = nltk.sent_tokenize(text)  #Tokenize to sentences \n",
    "    keywords = [nltk.word_tokenize(sentence) for sentence in text]\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(avoidwords)\n",
    "    for i in range(len(keywords)):\n",
    "        keywords[i] = [word for word in keywords[i] if word not in stop_words]\n",
    "    return keywords\n",
    "\n",
    "#Frame pre-processing function\n",
    "def prepro(frame,cap_or_bio,avoidwords):\n",
    "    frame2 = frame\n",
    "    for c in range(len(frame2)):\n",
    "        keywords = process(frame2[cap_or_bio][c],avoidwords)\n",
    "        frame2[cap_or_bio][c] = keywords\n",
    "    return frame2\n",
    "\n",
    "def flat(array):     # 2D array reduction\n",
    "    flatten_list = [j for sub in array for j in sub] \n",
    "    flatten_list = list(chain.from_iterable(flatten_list))\n",
    "    return flatten_list\n",
    "\n",
    "def soft_flat(array):     # 2D array reduction\n",
    "    flatten_list = [j for sub in array for j in sub] \n",
    "    return flatten_list\n",
    "\n",
    "\n",
    "# normalize() -> given an array, converts to 1/0, top int(pos) will be 1\n",
    "def normalize(keys, pos =3):  \n",
    "    ax = [i for i in keys]\n",
    "    temp = [i for i in keys]\n",
    "    temp.sort()\n",
    "    temp = temp[-pos:]\n",
    "    for x in temp:\n",
    "        ax[keys.index(x)] = 1\n",
    "    for x in range(len(ax)):\n",
    "        if ax[x] != 1:\n",
    "            ax[x] = 0\n",
    "    return ax\n",
    "\n",
    "def normalizeSD(keys, thre =3):    # Given score array return shortlisted cats in given threshold\n",
    "    ax = deviation(keys)\n",
    "    ax = dev_shortlist(ax)\n",
    "    return ax\n",
    "\n",
    "# compute() => category[] to be called outside\n",
    "def compute(caption,category,top =3):\n",
    "    ar = []\n",
    "    score = []\n",
    "\n",
    "    # Code to get frequency distribution and unique keywords array\n",
    "    keywords = []\n",
    "    caption_freq = []\n",
    "    counts = Counter(caption)\n",
    "    if len(counts) > 0:\n",
    "        labels, values = zip(*counts.items())\n",
    "        ## sort your values in descending order\n",
    "        indSort = np.argsort(values)[::-1]\n",
    "        ## rearrange your data\n",
    "        keywords = np.array(labels)[indSort]  # Label\n",
    "        caption_freq = np.array(values)[indSort]  # Values\n",
    "    \n",
    "    # Detect words not in Google Dict | Put freq = 0\n",
    "    for x in keywords:\n",
    "        try:\n",
    "            restConst = w.similarity(x,'something')\n",
    "        except KeyError:\n",
    "            caption_freq[np.where(keywords == x)] = 0\n",
    "        \n",
    "    #Google similaity function\n",
    "    for x in category:\n",
    "        empty = []\n",
    "        for y in keywords:\n",
    "            try:\n",
    "                empty.append(w.similarity(x,y))\n",
    "            except:\n",
    "                empty.append(0)\n",
    "        ar.append(empty)\n",
    "    \n",
    "    # Store the similarity values in dataframe\n",
    "    frame = pd.DataFrame()\n",
    "    frame = pd.DataFrame(ar, columns = keywords)\n",
    "    \n",
    "    \n",
    "    ### CHANGES  MADE\n",
    "    #Normalize | top select\n",
    "    for key in frame.columns:\n",
    "        frame[key] = normalizeSD(frame[key].tolist(),top)\n",
    "    \n",
    "    # Multiply with frequency\n",
    "    for row in range(len(frame)):\n",
    "        frame.values[row] = [i*j for i,j in zip(frame.values[row],caption_freq)]\n",
    "    # Sum the values => Score\n",
    "    for row in range(len(frame)):\n",
    "        score.append(sum(frame.values[row]))\n",
    "    \n",
    "    frame['category'] = category\n",
    "    frame['Scores'] = score\n",
    "    return frame,keywords[:6]\n",
    "\n",
    "def deviation(array):\n",
    "    mu = max(array)\n",
    "    l = len(array)\n",
    "    ar = []\n",
    "    for x in range(l):\n",
    "        ar.append(math.sqrt((array[x]-mu)**2)/l)\n",
    "    total = sum(ar)\n",
    "    for x in range(l):\n",
    "        if total != 0:\n",
    "            ar[x] = (ar[x]/total)*100\n",
    "    return ar\n",
    "\n",
    "def mean_deviation(array):\n",
    "    l = len(array)\n",
    "    mu = sum(array)/l\n",
    "    ar = []\n",
    "    for x in range(l):\n",
    "        ar.append(math.sqrt((array[x]-mu)**2)/l)\n",
    "    total = sum(ar)\n",
    "    for x in range(l):\n",
    "        if total != 0:\n",
    "            ar[x] = (ar[x]/total)*100\n",
    "    return ar\n",
    "\n",
    "def dev_shortlist(dev_array,thre = 2):  # Shortlist using threshold from deviation array | return array in 1/0\n",
    "    final_cat = [0]*len(dev_array)\n",
    "    for i in range(len(dev_array)):\n",
    "        if dev_array[i] <=thre:\n",
    "            final_cat[i] = 1\n",
    "    return final_cat\n",
    "\n",
    "def sort_cat(dev,cat, thre = 2):   # Shortlist using thre | Return category array\n",
    "    final_cat = []\n",
    "    for i in range(len(dev)):\n",
    "        if dev[i] <=thre:\n",
    "            final_cat.append(cat[i])\n",
    "    return final_cat\n",
    "\n",
    "def get_row_pscore(col_name,f1,i,f2, scoreType):  # f1-mainframe | f2-frame\n",
    "    ud = f1.at[i,'id']\n",
    "    ul = f1.at[i,'url']\n",
    "    row_in_array = [ud,ul]\n",
    "    dev_array = f2[scoreType].tolist()\n",
    "    row_in_array.extend(dev_array)\n",
    "    tk = f2.at[0,'Top keywords']\n",
    "    row_in_array.extend([tk])\n",
    "    zip_it = zip(col_name,row_in_array)\n",
    "    convert_to_dict = dict(zip_it)\n",
    "    return convert_to_dict\n",
    "\n",
    "def top_category(f2,categories,thre=2):\n",
    "    final_cat = [0]*len(categories)\n",
    "    dev_scores = f2['Deviation'].tolist()\n",
    "    rank_of_cat = 1\n",
    "    for i in range(len(dev_scores)):\n",
    "        if dev_scores[i] <=thre:\n",
    "            final_cat[i] = rank_of_cat \n",
    "            rank_of_cat = rank_of_cat +1\n",
    "    return final_cat\n",
    "\n",
    "def top_category_get_percent(f2,categories,thre=2):\n",
    "    final_cat = [0]*len(categories)\n",
    "    dev_scores = f2['Deviation'].tolist()\n",
    "    percent_array = f2['Percentage'].tolist()\n",
    "    for i in range(len(dev_scores)):\n",
    "        if dev_scores[i] <=thre:\n",
    "            final_cat[i] = percent_array[i]\n",
    "    return final_cat\n",
    "    \n",
    "    \n",
    "def get_row_result(col_name,f1,f2,rank_array):  # f1-mainframe\n",
    "    ud = f1.at[0,'user_id']\n",
    "    hd = f1.at[0,'handle']\n",
    "    fl = f1.at[0,'followers']\n",
    "    ul = f1.at[0,'url']\n",
    "    row_in_array = [ud,hd,fl,ul]\n",
    "    row_in_array.extend(rank_array)\n",
    "    tk = f2.at[0,'Top keywords']\n",
    "    row_in_array.extend([tk])\n",
    "    zip_it = zip(col_name,row_in_array)\n",
    "    convert_to_dict = dict(zip_it)\n",
    "    return convert_to_dict\n",
    "\n",
    "# To make data in \n",
    "# DB format | API post \n",
    "def to_dict_api(percentages,categories,top_keywords,frame,i): #frame and i to get id\n",
    "    mydict = {}\n",
    "    cat_array =[]\n",
    "    empty_percent = [0]*4\n",
    "    percent_array = [y for y in percentages]\n",
    "    percent_array.extend(empty_percent)\n",
    "    mydict['user_id'] = frame['id'].iloc[i]\n",
    "    mydict['keywords'] = json.dumps(top_keywords.tolist())\n",
    "    for i in range(len(categories)):\n",
    "        cat_array.append({'tag':categories[i],'percentage':percent_array[i]})\n",
    "    mydict['categories'] = json.dumps(cat_array)\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories\n",
    "categories = ['food', 'fashion', 'makeup', 'beauty', 'lifestyle','luxury', 'traveler','photography','fitness','sports','gaming', 'entertainment', 'technology','investment','education', 'animal', 'health']\n",
    "API_categories = ['Food','Fashion', 'Makeup', 'Beauty', 'Lifestyle','Luxury', 'Travel','Photography','Fitness','Sports','Gaming', 'Entertainment', 'Gadgets & Tech','Finance','Education', 'Animal/Pet', 'Health','Art', 'Self Improvement', 'Parenting', 'Books']\n",
    "\n",
    "# This required to run some function\n",
    "col_name = ['user_id','url','food', 'fashion', 'makeup', 'beauty', 'lifestyle','luxury', 'travel', 'photography','fitness','sports','gaming', 'entertainment', 'technology','investment','education', 'animal', 'health', 'parenting','top keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  5698\n",
      "<class 'dict'>\n",
      "{'user_id': 127, 'keywords': '[\"blogger\", \"styling\", \"travel\", \"curvy\", \"one\", \"also\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 8}, {\"tag\": \"Fashion\", \"percentage\": 11}, {\"tag\": \"Makeup\", \"percentage\": 12}, {\"tag\": \"Beauty\", \"percentage\": 12}, {\"tag\": \"Lifestyle\", \"percentage\": 5}, {\"tag\": \"Luxury\", \"percentage\": 6}, {\"tag\": \"Travel\", \"percentage\": 5}, {\"tag\": \"Photography\", \"percentage\": 5}, {\"tag\": \"Fitness\", \"percentage\": 5}, {\"tag\": \"Sports\", \"percentage\": 6}, {\"tag\": \"Gaming\", \"percentage\": 2}, {\"tag\": \"Entertainment\", \"percentage\": 4}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 3}, {\"tag\": \"Finance\", \"percentage\": 3}, {\"tag\": \"Education\", \"percentage\": 4}, {\"tag\": \"Animal/Pet\", \"percentage\": 3}, {\"tag\": \"Health\", \"percentage\": 5}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Before:  13400\n",
      "<class 'dict'>\n",
      "{'user_id': 128, 'keywords': '[\"lookbook\", \"one\", \"time\", \"make\", \"workout\", \"much\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 10}, {\"tag\": \"Fashion\", \"percentage\": 9}, {\"tag\": \"Makeup\", \"percentage\": 14}, {\"tag\": \"Beauty\", \"percentage\": 9}, {\"tag\": \"Lifestyle\", \"percentage\": 7}, {\"tag\": \"Luxury\", \"percentage\": 5}, {\"tag\": \"Travel\", \"percentage\": 2}, {\"tag\": \"Photography\", \"percentage\": 3}, {\"tag\": \"Fitness\", \"percentage\": 8}, {\"tag\": \"Sports\", \"percentage\": 5}, {\"tag\": \"Gaming\", \"percentage\": 2}, {\"tag\": \"Entertainment\", \"percentage\": 4}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 5}, {\"tag\": \"Finance\", \"percentage\": 3}, {\"tag\": \"Education\", \"percentage\": 4}, {\"tag\": \"Animal/Pet\", \"percentage\": 4}, {\"tag\": \"Health\", \"percentage\": 6}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Before:  4026\n",
      "<class 'dict'>\n",
      "{'user_id': 132, 'keywords': '[\"get\", \"new\", \"india\", \"look\", \"time\", \"love\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 7}, {\"tag\": \"Fashion\", \"percentage\": 10}, {\"tag\": \"Makeup\", \"percentage\": 12}, {\"tag\": \"Beauty\", \"percentage\": 10}, {\"tag\": \"Lifestyle\", \"percentage\": 5}, {\"tag\": \"Luxury\", \"percentage\": 8}, {\"tag\": \"Travel\", \"percentage\": 3}, {\"tag\": \"Photography\", \"percentage\": 3}, {\"tag\": \"Fitness\", \"percentage\": 8}, {\"tag\": \"Sports\", \"percentage\": 6}, {\"tag\": \"Gaming\", \"percentage\": 3}, {\"tag\": \"Entertainment\", \"percentage\": 6}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 5}, {\"tag\": \"Finance\", \"percentage\": 3}, {\"tag\": \"Education\", \"percentage\": 4}, {\"tag\": \"Animal/Pet\", \"percentage\": 3}, {\"tag\": \"Health\", \"percentage\": 4}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Before:  7351\n",
      "<class 'dict'>\n",
      "{'user_id': 134, 'keywords': '[\"pune\", \"love\", \"happy\", \"mumbai\", \"weekend\", \"blogger\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 6}, {\"tag\": \"Fashion\", \"percentage\": 13}, {\"tag\": \"Makeup\", \"percentage\": 12}, {\"tag\": \"Beauty\", \"percentage\": 11}, {\"tag\": \"Lifestyle\", \"percentage\": 6}, {\"tag\": \"Luxury\", \"percentage\": 7}, {\"tag\": \"Travel\", \"percentage\": 6}, {\"tag\": \"Photography\", \"percentage\": 4}, {\"tag\": \"Fitness\", \"percentage\": 6}, {\"tag\": \"Sports\", \"percentage\": 6}, {\"tag\": \"Gaming\", \"percentage\": 2}, {\"tag\": \"Entertainment\", \"percentage\": 7}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 3}, {\"tag\": \"Finance\", \"percentage\": 2}, {\"tag\": \"Education\", \"percentage\": 3}, {\"tag\": \"Animal/Pet\", \"percentage\": 2}, {\"tag\": \"Health\", \"percentage\": 3}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Before:  7957\n",
      "<class 'dict'>\n",
      "{'user_id': 135, 'keywords': '[\"fashionista\", \"aman\", \"traveler\", \"pic\", \"stories\", \"today\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 10}, {\"tag\": \"Fashion\", \"percentage\": 9}, {\"tag\": \"Makeup\", \"percentage\": 11}, {\"tag\": \"Beauty\", \"percentage\": 10}, {\"tag\": \"Lifestyle\", \"percentage\": 5}, {\"tag\": \"Luxury\", \"percentage\": 7}, {\"tag\": \"Travel\", \"percentage\": 5}, {\"tag\": \"Photography\", \"percentage\": 5}, {\"tag\": \"Fitness\", \"percentage\": 5}, {\"tag\": \"Sports\", \"percentage\": 6}, {\"tag\": \"Gaming\", \"percentage\": 2}, {\"tag\": \"Entertainment\", \"percentage\": 4}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 3}, {\"tag\": \"Finance\", \"percentage\": 3}, {\"tag\": \"Education\", \"percentage\": 5}, {\"tag\": \"Animal/Pet\", \"percentage\": 4}, {\"tag\": \"Health\", \"percentage\": 4}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Before:  11964\n",
      "<class 'dict'>\n",
      "{'user_id': 136, 'keywords': '[\"influencer\", \"makeup\", \"get\", \"code\", \"sugar\", \"skin\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 6}, {\"tag\": \"Fashion\", \"percentage\": 11}, {\"tag\": \"Makeup\", \"percentage\": 17}, {\"tag\": \"Beauty\", \"percentage\": 13}, {\"tag\": \"Lifestyle\", \"percentage\": 5}, {\"tag\": \"Luxury\", \"percentage\": 6}, {\"tag\": \"Travel\", \"percentage\": 3}, {\"tag\": \"Photography\", \"percentage\": 3}, {\"tag\": \"Fitness\", \"percentage\": 5}, {\"tag\": \"Sports\", \"percentage\": 5}, {\"tag\": \"Gaming\", \"percentage\": 2}, {\"tag\": \"Entertainment\", \"percentage\": 5}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 7}, {\"tag\": \"Finance\", \"percentage\": 4}, {\"tag\": \"Education\", \"percentage\": 3}, {\"tag\": \"Animal/Pet\", \"percentage\": 3}, {\"tag\": \"Health\", \"percentage\": 4}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Before:  15286\n",
      "<class 'dict'>\n",
      "{'user_id': 138, 'keywords': '[\"foodie\", \"food\", \"hai\", \"india\", \"ke\", \"kar\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 16}, {\"tag\": \"Fashion\", \"percentage\": 7}, {\"tag\": \"Makeup\", \"percentage\": 6}, {\"tag\": \"Beauty\", \"percentage\": 18}, {\"tag\": \"Lifestyle\", \"percentage\": 6}, {\"tag\": \"Luxury\", \"percentage\": 3}, {\"tag\": \"Travel\", \"percentage\": 5}, {\"tag\": \"Photography\", \"percentage\": 2}, {\"tag\": \"Fitness\", \"percentage\": 5}, {\"tag\": \"Sports\", \"percentage\": 4}, {\"tag\": \"Gaming\", \"percentage\": 3}, {\"tag\": \"Entertainment\", \"percentage\": 4}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 3}, {\"tag\": \"Finance\", \"percentage\": 2}, {\"tag\": \"Education\", \"percentage\": 5}, {\"tag\": \"Animal/Pet\", \"percentage\": 3}, {\"tag\": \"Health\", \"percentage\": 7}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Before:  11390\n",
      "<class 'dict'>\n",
      "{'user_id': 141, 'keywords': '[\"fashion\", \"men\", \"india\", \"style\", \"love\", \"like\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 5}, {\"tag\": \"Fashion\", \"percentage\": 14}, {\"tag\": \"Makeup\", \"percentage\": 12}, {\"tag\": \"Beauty\", \"percentage\": 11}, {\"tag\": \"Lifestyle\", \"percentage\": 5}, {\"tag\": \"Luxury\", \"percentage\": 6}, {\"tag\": \"Travel\", \"percentage\": 4}, {\"tag\": \"Photography\", \"percentage\": 6}, {\"tag\": \"Fitness\", \"percentage\": 5}, {\"tag\": \"Sports\", \"percentage\": 6}, {\"tag\": \"Gaming\", \"percentage\": 3}, {\"tag\": \"Entertainment\", \"percentage\": 5}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 6}, {\"tag\": \"Finance\", \"percentage\": 3}, {\"tag\": \"Education\", \"percentage\": 4}, {\"tag\": \"Animal/Pet\", \"percentage\": 3}, {\"tag\": \"Health\", \"percentage\": 4}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Before:  8188\n",
      "<class 'dict'>\n",
      "{'user_id': 142, 'keywords': '[\"makeup\", \"beauty\", \"skin\", \"link\", \"products\", \"bio\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 6}, {\"tag\": \"Fashion\", \"percentage\": 7}, {\"tag\": \"Makeup\", \"percentage\": 19}, {\"tag\": \"Beauty\", \"percentage\": 13}, {\"tag\": \"Lifestyle\", \"percentage\": 4}, {\"tag\": \"Luxury\", \"percentage\": 5}, {\"tag\": \"Travel\", \"percentage\": 2}, {\"tag\": \"Photography\", \"percentage\": 6}, {\"tag\": \"Fitness\", \"percentage\": 5}, {\"tag\": \"Sports\", \"percentage\": 4}, {\"tag\": \"Gaming\", \"percentage\": 3}, {\"tag\": \"Entertainment\", \"percentage\": 5}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 6}, {\"tag\": \"Finance\", \"percentage\": 3}, {\"tag\": \"Education\", \"percentage\": 3}, {\"tag\": \"Animal/Pet\", \"percentage\": 5}, {\"tag\": \"Health\", \"percentage\": 5}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Before:  14265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'user_id': 147, 'keywords': '[\"updates\", \"follow\", \"yummy\", \"tasty\", \"foodies\", \"dinner\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 27}, {\"tag\": \"Fashion\", \"percentage\": 7}, {\"tag\": \"Makeup\", \"percentage\": 6}, {\"tag\": \"Beauty\", \"percentage\": 11}, {\"tag\": \"Lifestyle\", \"percentage\": 4}, {\"tag\": \"Luxury\", \"percentage\": 3}, {\"tag\": \"Travel\", \"percentage\": 3}, {\"tag\": \"Photography\", \"percentage\": 2}, {\"tag\": \"Fitness\", \"percentage\": 6}, {\"tag\": \"Sports\", \"percentage\": 8}, {\"tag\": \"Gaming\", \"percentage\": 2}, {\"tag\": \"Entertainment\", \"percentage\": 9}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 2}, {\"tag\": \"Finance\", \"percentage\": 2}, {\"tag\": \"Education\", \"percentage\": 3}, {\"tag\": \"Animal/Pet\", \"percentage\": 2}, {\"tag\": \"Health\", \"percentage\": 4}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "Done 1 pages, the last_id is 147 and time taken 20.529696799999982 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>url</th>\n",
       "      <th>food</th>\n",
       "      <th>fashion</th>\n",
       "      <th>makeup</th>\n",
       "      <th>beauty</th>\n",
       "      <th>lifestyle</th>\n",
       "      <th>luxury</th>\n",
       "      <th>travel</th>\n",
       "      <th>photography</th>\n",
       "      <th>...</th>\n",
       "      <th>sports</th>\n",
       "      <th>gaming</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>technology</th>\n",
       "      <th>investment</th>\n",
       "      <th>education</th>\n",
       "      <th>animal</th>\n",
       "      <th>health</th>\n",
       "      <th>parenting</th>\n",
       "      <th>top keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>https://www.instagram.com/wannaeat16/</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>updates, follow, yummy, tasty, foodies, dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id                                    url food fashion makeup beauty  \\\n",
       "0     147  https://www.instagram.com/wannaeat16/   27       7      6     11   \n",
       "\n",
       "  lifestyle luxury travel photography  ... sports gaming entertainment  \\\n",
       "0         4      3      3           2  ...      8      2             9   \n",
       "\n",
       "  technology investment education animal health  \\\n",
       "0          2          2         3      2      4   \n",
       "\n",
       "                                        parenting top keywords  \n",
       "0  updates, follow, yummy, tasty, foodies, dinner          NaN  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "x = requests.get('http://44.229.68.155/insta_users/get_uncategorized_accounts?limit=10&current_id=0', headers={'Authorization': 'Token ruor7REQi9KJz6wIQKDXvwtt'})\n",
    "status = x.status_code\n",
    "data = x.json()\n",
    "df = pd.DataFrame(data['users'])\n",
    "pages = 0\n",
    "idsdone = 0\n",
    "txt = \"Done {} pages, the last_id is {} and time taken {} seconds\"\n",
    "\n",
    "while(len(data['users']) !=0 and pages<1):\n",
    "    try:\n",
    "        new_tic = time.perf_counter()\n",
    "        if(status != 200):\n",
    "            raise Exception(\"GET request error: {}\".format(status))\n",
    "        dfnew = pd.DataFrame(columns=['id','handle','name','url','gender','country','captions'], data = df[['id','handle','name','url','gender','country','captions']].values)\n",
    "        last_id = dfnew['id'].iloc[-1]\n",
    "\n",
    "        # Main Categorization # \n",
    "        for i in range(len(dfnew)):\n",
    "\n",
    "            try:\n",
    "                #Store userid | caption | total posts\n",
    "                userid = dfnew['id'].iloc[i]\n",
    "                captions = dfnew['captions'].iloc[i]\n",
    "                total_posts = len(captions)\n",
    "\n",
    "                # Words which mostly occurs in insta post and we want to avoid considering them for the sake of accuracy of results\n",
    "                avoidwords = ['verified','none']\n",
    "\n",
    "                # Fresh dataframe\n",
    "                profile_percentages =  pd.DataFrame(columns = ['user_id','url','food', 'fashion', 'makeup', 'beauty', 'lifestyle','luxury', 'travel', 'photography','fitness','sports','gaming', 'entertainment', 'technology','investment','education', 'animal','health', 'parenting','top keywords'])\n",
    "\n",
    "                #Converting to keywords\n",
    "                captions = process(captions,avoidwords)\n",
    "                caption_array = soft_flat(captions)\n",
    "                print(\"Before: \",len(caption_array))\n",
    "                #Temporary array i-> interim\n",
    "                icaption_array = [i for i in caption_array]\n",
    "                # Removing words not in dictionary also single characters\n",
    "                for x in caption_array:\n",
    "                    try:\n",
    "                        checkword = w.similarity(x,'something') #Check word if exist in googlenews\n",
    "                        if len(x) <2: #Removing single character\n",
    "                            icaption_array.pop(icaption_array.index(x))\n",
    "                    except KeyError:\n",
    "                        icaption_array.pop(icaption_array.index(x))\n",
    "                #Restore Array\n",
    "                caption_array = [i for i in icaption_array]\n",
    "\n",
    "                if len(caption_array) ==0:\n",
    "                    raise Exception(\"No Words in profile for categorization or Different language\")\n",
    "\n",
    "                # Punishing accounts which has less than 1.5 words in caption\n",
    "                if len(caption_array) < 2*(total_posts):\n",
    "                    raise Exception(\"Too less words for categorization\")\n",
    "\n",
    "                # Word2vec computation\n",
    "                frame = pd.DataFrame()\n",
    "                frame, top_keywords = compute(caption_array,categories,3)\n",
    "\n",
    "                #Convert to Percentage\n",
    "                per = frame['Scores'].tolist()\n",
    "                per_sum = sum(per)\n",
    "                for x in range(len(per)):\n",
    "                    per[x] = round((per[x]/per_sum)*100)\n",
    "                frame['Percentage'] = per\n",
    "                frame['Top keywords'] = ', '.join(top_keywords)\n",
    "\n",
    "                #Store profile percentage\n",
    "                row_df_5 = get_row_pscore(col_name,dfnew,i,frame,'Percentage')\n",
    "                profile_percentages = profile_percentages.append(row_df_5,ignore_index=True)\n",
    "\n",
    "                # POST API Request\n",
    "                file = to_dict_api(frame['Percentage'].tolist(),API_categories,top_keywords,dfnew,i)\n",
    "    #             url = 'http://44.229.68.155/insta_user/add_category_to_insta_user'\n",
    "    #             y = requests.post(url, data = file,headers={'Authorization': 'Token ruor7REQi9KJz6wIQKDXvwtt'})\n",
    "\n",
    "    #             if y.status_code !=200:\n",
    "    #                 raise Exception(\"Post request error {}\".format(y.status_code))\n",
    "\n",
    "                profile_percentages.to_csv(r'C:\\Users\\acer\\Downloads\\perAPI1.csv')\n",
    "                print(type(file))\n",
    "                print(file)\n",
    "                idsdone = idsdone +1\n",
    "\n",
    "            except Exception as Argument:\n",
    "                # creating/opening a file \n",
    "                f = open(r\"C:\\Users\\acer\\Downloads\\errorfile.txt\", \"a\") \n",
    "                # writing in the file \n",
    "                f.write(\"Userid\\t\"+str(userid)+\"\\t: \"+str(Argument)+str(\"\\n\")) \n",
    "                # closing the file \n",
    "                f.close()  \n",
    "\n",
    "        # END of Main Categorization #\n",
    "\n",
    "        pages = pages +1\n",
    "        toc = time.perf_counter()\n",
    "        print(txt.format(pages,last_id,toc-new_tic))\n",
    "        # Request new page\n",
    "        x = requests.get('http://44.229.68.155/insta_users/get_uncategorized_accounts?limit=10&current_id='+str(last_id), headers={'Authorization': 'Token ruor7REQi9KJz6wIQKDXvwtt'})\n",
    "        data = x.json()\n",
    "        df = pd.DataFrame(data['users'])\n",
    "        status = x.status_code\n",
    "    \n",
    "    except Exception as Argument:\n",
    "        # creating/opening a file \n",
    "        f = open(r\"C:\\Users\\acer\\Downloads\\errorfile.txt\", \"a\") \n",
    "        # writing in the file \n",
    "        f.write(\"Currently in \"+str(pages)+\"\\t\"+str(Argument)+str(\"\\n\")) \n",
    "        # closing the file \n",
    "        f.close()  \n",
    "    \n",
    "    \n",
    "\n",
    "toc = time.perf_counter()\n",
    "f = open(r\"C:\\Users\\acer\\Downloads\\errorfile.txt\", \"a\") \n",
    "# writing in the file \n",
    "f.write(\"The model ran in \"+str(toc - tic)+\" seconds\"+str(\"\\n\")) \n",
    "f.write(\"Total ids done: \"+str(idsdone))\n",
    "# closing the file \n",
    "f.close() \n",
    "display(profile_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  5531\n",
      "After:  2467\n",
      "['peri', 'peri', 'chicken', 'cone', 'chicago', 'chimney', 'noida', 'sector', 'foodie', 'food', 'updates', 'noida', 'foodie', 'blogger', 'lit', 'cones', 'lit', 'insta', 'foodies', 'momos', 'travelers', 'caf', 'noida', 'foodie', 'food', 'updates', 'noida', 'foodie', 'blogger', 'lit', 'momos', 'travelers', 'lit', 'insta', 'foodies', 'maharaja', 'thali', 'vega', 'pure', 'vegetarian', 'restaurant', 'cp', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'cp', 'lit', 'insta', 'foodies', 'sarson', 'da', 'saag', 'di', 'roti', 'delhi', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'lit', 'insta', 'foodies', 'steamed', 'chicken', 'chicken', 'near', 'bus', 'stand', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'lit', 'insta', 'foodies', 'dal', 'makhni', 'brown', 'rice', 'garlic', 'aloo', 'chicken', 'leg', 'biryani', 'paneer', 'tikka', 'masala', 'veggies', 'brown', 'rice', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'food', 'lit', 'insta', 'foodies', 'chat', 'raj', 'kachori', 'moong', 'dal', 'halwa', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'food', 'lit', 'insta', 'foodies', 'egg', 'biryani', 'paneer', 'butter', 'masala', 'biryani', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'food', 'lit', 'insta', 'foodies', 'crunchy', 'potato', 'skins', 'homemade', 'delhi', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'homemade', 'food', 'lit', 'insta', 'foodies', 'quarantine', 'veg', 'momos', 'homemade', 'delhi', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'homemade', 'food', 'lit', 'insta', 'foodies', 'quarantine', 'roasted', 'butter', 'chicken', 'homemade', 'delhi', 'foodie', 'food', 'updates', 'quarantine', 'cooking', 'delhi', 'foodie', 'blogger', 'lit', 'homemade', 'food', 'lit', 'insta', 'foodies', 'quarantine', 'chole', 'homemade', 'delhi', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'homemade', 'food', 'lit', 'insta', 'foodies', 'quarantine', 'weekend', 'blue', 'parrot', 'cafe', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'pasta', 'insta', 'foodies', 'food', 'love', 'pancakes', 'blue', 'door', 'khan', 'market', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'breakfast', 'pancakes', 'lit', 'insta', 'foodies', 'nachos', 'burger', 'love', 'grill', 'hudson', 'lane', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'burger', 'nachos', 'lit', 'insta', 'foodies', 'cheese', 'corn', 'dumplings', 'ching', 'noida', 'follow', 'foodie', 'food', 'updates', 'noida', 'foodie', 'blogger', 'lit', 'dumplings', 'lit', 'insta', 'foodies', 'breakfast', 'like', 'homemade', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'pancake', 'homemade', 'insta', 'foodies', 'food', 'wali', 'chai', 'strawberry', 'lassi', 'samosa', 'chat', 'baked', 'tandoori', 'mac', 'cheese', 'green', 'park', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'food', 'kaju', 'idli', 'homemade', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'homemade', 'breakfast', 'insta', 'foodies', 'food', 'evening', 'snack', 'time', 'mumbai', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'bombay', 'lit', 'insta', 'foodies', 'food', 'thai', 'hed', 'tod', 'sauce', 'sam', 'rod', 'dinner', 'thai', 'embassy', 'delhi', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'snacks', 'thailand', 'lit', 'insta', 'foodies', 'cheesy', 'garlic', 'bread', 'wow', 'sandwiches', 'south', 'ex', 'part', 'near', 'macdonald', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'snack', 'lit', 'cheese', 'insta', 'foodies', 'coffee', 'time', 'essex', 'farms', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'coffee', 'insta', 'foodies', 'food', 'cheese', 'capsicum', 'onion', 'pizza', 'cheesy', 'garlic', 'bread', 'french', 'fries', 'cp', 'block', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'cp', 'insta', 'foodies', 'food', 'veg', 'platter', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'food', 'chole', 'olive', 'oil', 'tikki', 'wala', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'snack', 'lit', 'btw', 'breakfast', 'insta', 'foodies', 'cheese', 'burst', 'momos', 'chi', 'block', 'market', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'momos', 'snack', 'veg', 'insta', 'foodies', 'food', 'snacking', 'best', 'noida', 'sector', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'snacks', 'noida', 'insta', 'foodies', 'spicy', 'peri', 'peri', 'shake', 'fries', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'fries', 'veg', 'spicy', 'insta', 'foodies', 'chicken', 'breast', 'black', 'pepper', 'sauce', 'potato', 'wedges', 'met', 'noida', 'sector', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'food', 'repost', 'get', 'repost', 'moment', 'love', 'lasts', 'eternity', 'come', 'live', 'eternity', 'mein', 'haath', 'nitish', 'featuring', 'may', 'leading', 'music', 'streaming', 'platforms', 'modeling', 'actor', 'musicvideo', 'crispy', 'chicken', 'burger', 'egg', 'bistro', 'near', 'amity', 'noida', 'sector', 'rs', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'chicken', 'burger', 'noida', 'insta', 'chicken', 'shawarma', 'pita', 'bread', 'royal', 'shawarma', 'west', 'mumbai', 'opposite', 'ccd', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'snack', 'roll', 'cheese', 'filling', 'meal', 'insta', 'black', 'pav', 'bhaji', 'maruti', 'pav', 'bhaji', 'vile', 'price', 'rs', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'veg', 'insta', 'foodies', 'bun', 'maska', 'chai', 'caf', 'goodluck', 'gymkhana', 'follow', 'foodie', 'food', 'updates', 'pune', 'foodie', 'blogger', 'lit', 'breakfast', 'gymkhana', 'insta', 'foodies', 'grilled', 'chicken', 'steak', 'sizzler', 'amuse', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'sizzler', 'rice', 'veggies', 'insta', 'foodies', 'fried', 'idli', 'khas', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veg', 'idli', 'insta', 'foodies', 'desi', 'ghee', 'jalebi', 'old', 'delhi', 'famous', 'jalebi', 'wala', 'chowk', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'jalebi', 'dessert', 'insta', 'foodies', 'half', 'fried', 'khan', 'omelette', 'chowk', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'eggs', 'insta', 'foodies', 'peri', 'peri', 'grilled', 'chicken', 'nando', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'meal', 'insta', 'foodies', 'tandoori', 'tandoori', 'chai', 'krishna', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'roasted', 'butter', 'chicken', 'tikka', 'serve', 'amazing', 'food', 'online', 'since', 'outlet', 'across', 'delhi', 'food', 'festival', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'jama', 'masjid', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'dessert', 'veg', 'insta', 'foodies', 'food', 'malai', 'soya', 'tawa', 'roti', 'coke', 'ramesh', 'dhaba', 'colony', 'near', 'domino', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'dinner', 'veg', 'insta', 'foodies', 'food', 'mix', 'chat', 'sharma', 'chat', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'chat', 'chutneys', 'insta', 'foodies', 'white', 'sauce', 'pasta', 'ministry', 'games', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'pasta', 'italian', 'insta', 'foodies', 'seekh', 'kebabs', 'kebabs', 'west', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'kebabs', 'insta', 'foodies', 'chicken', 'tikka', 'safe', 'caterers', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'tikka', 'staters', 'insta', 'kebab', 'roti', 'noor', 'hotel', 'mohammad', 'ali', 'road', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'kebab', 'soft', 'meal', 'insta', 'veg', 'signature', 'bruschetta', 'sandwich', 'factory', 'phase', 'rs', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'bruschetta', 'signature', 'snack', 'veggie', 'cheese', 'filling', 'meal', 'insta', 'hulk', 'sandwich', 'om', 'snacks', 'mumbai', 'pure', 'veg', 'outlet', 'metro', 'station', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'snack', 'sandwich', 'cheese', 'filling', 'meal', 'insta', 'masala', 'cuppa', 'noodles', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'snack', 'nestle', 'breaktime', 'meal', 'insta', 'ghar', 'ka', 'khana', 'mumbai', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'dal', 'dinner', 'meal', 'insta', 'taco', 'back', 'domino', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'taco', 'mexican', 'snack', 'crispy', 'insta', 'good', 'morning', 'foodies', 'kulcha', 'lal', 'wala', 'green', 'rs', 'per', 'post', 'wishlist', 'follow', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'chole', 'punjab', 'insta', 'perfect', 'lunch', 'dal', 'makhani', 'tawa', 'soya', 'chur', 'chur', 'naan', 'butter', 'roti', 'chicken', 'tikka', 'echoes', 'hudson', 'lane', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'chicken', 'echoes', 'insta', 'pizza', 'dosa', 'spicy', 'possible', 'noida', 'sector', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'noida', 'dosa', 'veg', 'insta', 'foodies', 'food', 'peri', 'peri', 'veg', 'naan', 'nando', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veg', 'insta', 'foodies', 'food', 'lamb', 'pho', 'king', 'champa', 'gali', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'lamb', 'insta', 'foodies', 'food', 'bread', 'pakora', 'gopal', 'sweets', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'snacktime', 'panner', 'aloo', 'insta', 'foodies', 'food', 'plain', 'dosa', 'soda', 'fc', 'road', 'pune', 'follow', 'foodie', 'food', 'updates', 'pune', 'foodie', 'blogger', 'lit', 'dosa', 'insta', 'foodies', 'food', 'pav', 'bhaji', 'pav', 'bhaji', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'butter', 'pav', 'insta', 'foodies', 'food', 'breakfast', 'like', 'ss', 'kulcha', 'corner', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'food', 'breakfast', 'like', 'samaj', 'civil', 'lines', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'dhokla', 'insta', 'foodies', 'food', 'waffle', 'blueberry', 'waffle', 'gk', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'waffle', 'gk', 'blueberry', 'insta', 'foodies', 'food', 'malai', 'nut', 'town', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'food', 'starters', 'noida', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'staters', 'noida', 'matar', 'insta', 'foodies', 'food', 'near', 'golden', 'temple', 'follow', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'snack', 'insta', 'foodies', 'food', 'cassata', 'pastry', 'pastry', 'shop', 'krishna', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'dessert', 'pastry', 'insta', 'foodies', 'food', 'kebab', 'lucknow', 'follow', 'foodie', 'food', 'updates', 'lucknow', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'food', 'veg', 'cheese', 'dosa', 'madras', 'idli', 'fries', 'shree', 'moi', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'moi', 'lunch', 'insta', 'foodies', 'food', 'orange', 'slush', 'ice', 'cream', 'golden', 'fiesta', 'central', 'market', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'slush', 'insta', 'foodies', 'food', 'perfect', 'lunch', 'hudson', 'lane', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'paneer', 'insta', 'foodies', 'food', 'stuffed', 'mushrooms', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'starters', 'insta', 'foodies', 'food', 'farmer', 'burger', 'champa', 'gali', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'burger', 'starters', 'insta', 'foodies', 'food', 'desi', 'ghee', 'roti', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'food', 'veg', 'thali', 'namo', 'foods', 'noida', 'sector', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'thali', 'noida', 'naan', 'insta', 'foodies', 'food', 'ice', 'cream', 'jack', 'chill', 'gk', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'icecream', 'gk', 'insta', 'foodies', 'food', 'masala', 'kulcha', 'kulcha', 'junction', 'cp', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'cp', 'insta', 'foodies', 'food', 'meal', 'spicy', 'veg', 'fries', 'green', 'apple', 'ice', 'tea', 'mcdonald', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'cp', 'mcdonalds', 'insta', 'foodies', 'food', 'mutton', 'korma', 'roti', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'korma', 'insta', 'foodies', 'food', 'afghani', 'shawarma', 'roll', 'afghani', 'shawarma', 'market', 'noida', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'snacktime', 'noida', 'roll', 'spicy', 'insta', 'foodies', 'food', 'brunch', 'time', 'caf', 'mg', 'road', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'pizza', 'insta', 'foodies', 'food', 'cheesy', 'fries', 'black', 'jack', 'punjabi', 'bagh', 'club', 'road', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'cheese', 'veg', 'insta', 'foodies', 'food', 'watering', 'chicken', 'tikka', 'seekh', 'kebabs', 'janta', 'meat', 'shop', 'colony', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'kebabs', 'insta', 'foodies', 'food', 'dinner', 'chicken', 'butter', 'naan', 'foods', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'dinner', 'insta', 'foodies', 'food', 'chicken', 'shawarma', 'manish', 'eating', 'point', 'nagar', 'lucknow', 'follow', 'foodie', 'food', 'updates', 'lucknow', 'foodie', 'blogger', 'lit', 'snack', 'insta', 'foodies', 'food', 'veg', 'chinese', 'chat', 'golden', 'fiesta', 'nagar', 'central', 'market', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'snack', 'veg', 'insta', 'foodies', 'food', 'veg', 'tandoori', 'momos', 'noida', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'noida', 'momos', 'snack', 'veg', 'insta', 'foodies', 'food', 'tandoori', 'soya', 'tikka', 'kebab', 'colony', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'soyabean', 'snack', 'veg', 'insta', 'foodies', 'food', 'corn', 'tikka', 'hudson', 'lane', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'corn', 'snack', 'insta', 'foodies', 'food', 'cheesecake', 'paradise', 'blackjack', 'punjabi', 'bagh', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'shake', 'heaven', 'insta', 'foodies', 'food', 'chicken', 'tikka', 'bombay', 'brasserie', 'cp', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'cp', 'starter', 'heaven', 'insta', 'foodies', 'food', 'repost', 'get', 'repost', 'mein', 'haath', 'nitish', 'featuring', 'may', 'zee', 'music', 'leading', 'music', 'streaming', 'platforms', 'musicvideo', 'repost', 'get', 'repost', 'presenting', 'look', 'upcoming', 'music', 'video', 'mein', 'haath', 'nitish', 'featuring', 'may', 'leading', 'music', 'streaming', 'platforms', 'modeling', 'actor', 'musicvideo', 'repost', 'get', 'repost', 'hey', 'glad', 'announce', 'first', 'video', 'song', 'beautifully', 'sung', 'artists', 'nitish', 'please', 'like', 'share', 'comment', 'link', 'bio', 'thanks', 'modeling', 'actor', 'musicvideo', 'love', 'south', 'veg', 'metro', 'rs', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'delicious', 'bombay', 'style', 'vada', 'pav', 'pradeep', 'pav', 'bhaji', 'phase', 'mother', 'dairy', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'spicy', 'chutney', 'insta', 'may', 'every', 'diya', 'light', 'today', 'light', 'way', 'success', 'happiness', 'sending', 'way', 'love', 'laughter', 'good', 'wishes', 'joy', 'happy', 'diwali', 'chilling', 'scenes', 'hotels', 'bagh', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'staycation', 'snacks', 'hotel', 'mocktails', 'insta', 'om', 'chole', 'sector', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'snack', 'chole', 'meal', 'insta', 'cheesy', 'mexican', 'salsa', 'nachos', 'kuch', 'bhi', 'chalega', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'nachos', 'veg', 'starters', 'insta', 'chole', 'vijay', 'nagar', 'wala', 'rs', 'follow', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'samosa', 'veg', 'insta', 'oreo', 'shake', 'kuch', 'bhi', 'chalega', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'shake', 'insta', 'foodies', 'chicken', 'tikka', 'echoes', 'hudson', 'lane', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'tandoori', 'insta', 'cafe', 'foodies', 'spanish', 'omelette', 'sports', 'club', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'protein', 'insta', 'foodies', 'masala', 'dosa', 'anand', 'stall', 'ville', 'parle', 'near', 'college', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'dosa', 'insta', 'foodies', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'starters', 'insta', 'foodies', 'chocolate', 'walnut', 'brownie', 'ministry', 'games', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'dessert', 'chocolate', 'insta', 'foodies', 'keema', 'pao', 'german', 'bakery', 'park', 'follow', 'foodie', 'food', 'updates', 'pune', 'foodie', 'blogger', 'lit', 'kp', 'keema', 'insta', 'foodies', 'indian', 'snacks', 'best', 'caf', 'goodluck', 'gymkhana', 'follow', 'foodie', 'food', 'updates', 'pune', 'foodie', 'blogger', 'lit', 'snacks', 'break', 'gymkhana', 'insta', 'foodies', 'butter', 'chicken', 'butter', 'naan', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'naan', 'insta', 'foodies', 'paneer', 'pizza', 'oven', 'story', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'veg', 'veggies', 'pizza', 'insta', 'foodies', 'dinner', 'nitish', 'brothers', 'east', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'veg', 'dinner', 'insta', 'foodies', 'nasi', 'goreng', 'pho', 'king', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'asian', 'insta', 'foodies', 'aloo', 'samosa', 'snacks', 'mandi', 'house', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veg', 'snack', 'insta', 'foodies', 'morning', 'breakfast', 'like', 'home', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veg', 'home', 'bun', 'insta', 'foodies', 'dahi', 'ke', 'zikr', 'ka', 'noida', 'sector', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veg', 'veggies', 'noida', 'amity', 'insta', 'foodies', 'honey', 'chilli', 'potatoes', 'singapore', 'fried', 'rice', 'china', 'town', 'market', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veggies', 'insta', 'foodies', 'fried', 'chicken', 'chicken', 'point', 'shop', 'next', 'restaurant', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'spicy', 'insta', 'foodies', 'moong', 'dal', 'stuffed', 'cheese', 'pizza', 'stall', 'opposite', 'music', 'school', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veg', 'ito', 'insta', 'foodies', 'dutch', 'apple', 'pastry', 'big', 'chill', 'mall', 'india', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'pastry', 'dessert', 'chocolate', 'insta', 'foodies', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'mix', 'aloo', 'insta', 'foodies', 'donuts', 'mad', 'donuts', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'donuts', 'choco', 'dessert', 'insta', 'foodies', 'tandoori', 'chicken', 'chicken', 'gate', 'follow', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'butter', 'spicy', 'snack', 'insta', 'foodies', 'desi', 'sabzi', 'tandoori', 'roti', 'garam', 'dharam', 'follow', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'sabzi', 'spicy', 'dinner', 'insta', 'foodies', 'nachos', 'salad', 'sniper', 'bar', 'lounge', 'follow', 'foodie', 'food', 'updates', 'foodie', 'blogger', 'lit', 'snack', 'insta', 'foodies', 'one', 'think', 'well', 'love', 'well', 'sleep', 'well', 'one', 'dined', 'well', 'cocoa', 'yogurt', 'gk', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'dessert', 'insta', 'foodies', 'chole', 'sweets', 'restaurant', 'colony', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'restaurant', 'dessert', 'insta', 'foodies', 'hotdog', 'street', 'food', 'stall', 'near', 'gulab', 'sweets', 'krishna', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'hotdog', 'insta', 'foodies', 'italian', 'patty', 'pastry', 'krishna', 'nagar', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'patty', 'veg', 'insta', 'foodies', 'dahi', 'ke', 'kebab', 'pho', 'king', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veg', 'insta', 'foodies', 'chur', 'chur', 'naan', 'thali', 'junction', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veg', 'insta', 'foodies', 'fish', 'fingers', 'caf', 'mg', 'road', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'insta', 'foodies', 'food', 'vietnamese', 'iced', 'coffee', 'cafe', 'pho', 'king', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'veg', 'insta', 'foodies', 'food', 'breakfast', 'like', 'chole', 'matar', 'chole', 'cp', 'follow', 'foodie', 'food', 'updates', 'delhi', 'foodie', 'blogger', 'lit', 'cp', 'breakfast', 'veg', 'insta', 'foodies', 'food', 'sardar', 'pav', 'bhaji', 'sardar', 'follow', 'foodie', 'food', 'updates', 'mumbai', 'foodie', 'blogger', 'lit', 'snack', 'veg', 'insta', 'foodies', 'food']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "check = []\n",
    "captions = dfnew['captions'].iloc[9]\n",
    "captions = process(captions,avoidwords)\n",
    "caption_array = soft_flat(captions)\n",
    "print(\"Before: \",len(caption_array))\n",
    "#Temporary array i-> interim\n",
    "icaption_array = [i for i in caption_array]\n",
    "# Removing words not in dictionary\n",
    "for x in caption_array:\n",
    "    try:\n",
    "        checkword = w.similarity(x,'something') #Check word if exist in googlenews\n",
    "        if len(x) <2: #Removing single character\n",
    "            icaption_array.pop(icaption_array.index(x))\n",
    "    except KeyError:\n",
    "        icaption_array.pop(icaption_array.index(x))\n",
    "#Restore Array\n",
    "caption_array = [i for i in icaption_array]\n",
    "print(\"After: \",len(caption_array))\n",
    "print(caption_array)\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 145, 'keywords': '[\"hello\", \"hi\", \"bye\", \"itstime\"]', 'categories': '[{\"tag\": \"food\", \"percentage\": 2}, {\"tag\": \"fashion\", \"percentage\": 16}, {\"tag\": \"makeup\", \"percentage\": 11}, {\"tag\": \"beauty\", \"percentage\": 10}, {\"tag\": \"lifestyle\", \"percentage\": 3}, {\"tag\": \"luxury\", \"percentage\": 6}, {\"tag\": \"traveler\", \"percentage\": 2}, {\"tag\": \"photography\", \"percentage\": 7}, {\"tag\": \"fitness\", \"percentage\": 5}, {\"tag\": \"sports\", \"percentage\": 8}, {\"tag\": \"gaming\", \"percentage\": 2}, {\"tag\": \"entertainment\", \"percentage\": 5}, {\"tag\": \"technology\", \"percentage\": 5}, {\"tag\": \"investment\", \"percentage\": 1}, {\"tag\": \"education\", \"percentage\": 5}, {\"tag\": \"animal\", \"percentage\": 4}, {\"tag\": \"health\", \"percentage\": 5}, {\"tag\": \"infant\", \"percentage\": 3}]'}\n"
     ]
    }
   ],
   "source": [
    "sc = [2,16,11,10,3,6,2,7,5,8,2,5,5,1,5,4,5,3]\n",
    "# dic = {}\n",
    "# dic['id'] = 123\n",
    "# dic['keyword'] = \"kjdf\"\n",
    "# # print(dic)\n",
    "# cat_dic =[]\n",
    "# for i in range(len(categories)):\n",
    "#     cat_dic.append({'tag':categories[i],'percentage':sc[i]})\n",
    "# dic['cat'] = cat_dic\n",
    "# # print(cat_dic)\n",
    "# dicn = json.dumps(dic)\n",
    "# # print(dicn)\n",
    "frame = pd.DataFrame(columns = ['id'])\n",
    "frame['id']= [145,45,5]\n",
    "keys = np.array([\"hello\",\"hi\",\"bye\",\"its\" \"time\"])\n",
    "\n",
    "hhh = to_dict_api(sc,categories,keys,frame,0)\n",
    "print(hhh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 5, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "qw = [0]*4\n",
    "er = [25,5]\n",
    "percent_array = [y for y in er]\n",
    "percent_array.extend(qw)\n",
    "print(percent_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 237, 'keywords': '[\"india\", \"wedding\", \"ig\", \"photographers\", \"fashion\", \"photography\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 3}, {\"tag\": \"Fashion\", \"percentage\": 12}, {\"tag\": \"Makeup\", \"percentage\": 4}, {\"tag\": \"Beauty\", \"percentage\": 16}, {\"tag\": \"Lifestyle\", \"percentage\": 7}, {\"tag\": \"Luxury\", \"percentage\": 5}, {\"tag\": \"Travel\", \"percentage\": 4}, {\"tag\": \"Photography\", \"percentage\": 13}, {\"tag\": \"Fitness\", \"percentage\": 2}, {\"tag\": \"Sports\", \"percentage\": 5}, {\"tag\": \"Gaming\", \"percentage\": 7}, {\"tag\": \"Entertainment\", \"percentage\": 6}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 4}, {\"tag\": \"Finance\", \"percentage\": 3}, {\"tag\": \"Education\", \"percentage\": 3}, {\"tag\": \"Animal/Pet\", \"percentage\": 2}, {\"tag\": \"Health\", \"percentage\": 4}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
      "{\"status\":true}\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "file = {'user_id': 237, 'keywords': '[\"india\", \"wedding\", \"ig\", \"photographers\", \"fashion\", \"photography\"]', 'categories': '[{\"tag\": \"Food\", \"percentage\": 3}, {\"tag\": \"Fashion\", \"percentage\": 12}, {\"tag\": \"Makeup\", \"percentage\": 4}, {\"tag\": \"Beauty\", \"percentage\": 16}, {\"tag\": \"Lifestyle\", \"percentage\": 7}, {\"tag\": \"Luxury\", \"percentage\": 5}, {\"tag\": \"Travel\", \"percentage\": 4}, {\"tag\": \"Photography\", \"percentage\": 13}, {\"tag\": \"Fitness\", \"percentage\": 2}, {\"tag\": \"Sports\", \"percentage\": 5}, {\"tag\": \"Gaming\", \"percentage\": 7}, {\"tag\": \"Entertainment\", \"percentage\": 6}, {\"tag\": \"Gadgets & Tech\", \"percentage\": 4}, {\"tag\": \"Finance\", \"percentage\": 3}, {\"tag\": \"Education\", \"percentage\": 3}, {\"tag\": \"Animal/Pet\", \"percentage\": 2}, {\"tag\": \"Health\", \"percentage\": 4}, {\"tag\": \"Art\", \"percentage\": 0}, {\"tag\": \"Self Improvement\", \"percentage\": 0}, {\"tag\": \"Parenting\", \"percentage\": 0}, {\"tag\": \"Books\", \"percentage\": 0}]'}\n",
    "print(file)\n",
    "url = 'http://44.229.68.155/insta_user/add_category_to_insta_user'\n",
    "x = requests.post(url, data = file,headers={'Authorization': 'Token ruor7REQi9KJz6wIQKDXvwtt'})\n",
    "print(x.text)\n",
    "print(x.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>handle</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>email</th>\n",
       "      <th>secondary_email</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>avg_engagement</th>\n",
       "      <th>avg_likes</th>\n",
       "      <th>...</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>winkl_curated_by</th>\n",
       "      <th>winkl_curated_at</th>\n",
       "      <th>avg_video_views</th>\n",
       "      <th>keywords</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>294240</td>\n",
       "      <td>itssachinofficial</td>\n",
       "      <td>Sachin Vashist</td>\n",
       "      <td>https://www.instagram.com/itssachinofficial/</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020-10-22T16:41:29.289+05:30</td>\n",
       "      <td>2020-12-10T23:03:13.593+05:30</td>\n",
       "      <td>2.92</td>\n",
       "      <td>8330.25</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>India</td>\n",
       "      <td>Male</td>\n",
       "      <td>None</td>\n",
       "      <td>26</td>\n",
       "      <td>2020-10-22T16:43:55.170+05:30</td>\n",
       "      <td>7227.285714</td>\n",
       "      <td>[\"photography\", \"blogger\", \"lifestyle\", \"actor...</td>\n",
       "      <td>[Those who fly solo have the strongest wings.\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             handle            name  \\\n",
       "0  294240  itssachinofficial  Sachin Vashist   \n",
       "\n",
       "                                            url email secondary_email  \\\n",
       "0  https://www.instagram.com/itssachinofficial/  None                   \n",
       "\n",
       "                      created_at                     updated_at  \\\n",
       "0  2020-10-22T16:41:29.289+05:30  2020-12-10T23:03:13.593+05:30   \n",
       "\n",
       "   avg_engagement  avg_likes  ...  city state  country gender phone_number  \\\n",
       "0            2.92    8330.25  ...  None  None    India   Male         None   \n",
       "\n",
       "  winkl_curated_by               winkl_curated_at avg_video_views  \\\n",
       "0               26  2020-10-22T16:43:55.170+05:30     7227.285714   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [\"photography\", \"blogger\", \"lifestyle\", \"actor...   \n",
       "\n",
       "                                            captions  \n",
       "0  [Those who fly solo have the strongest wings.\\...  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "x = requests.get('http://44.229.68.155/insta_users/get_uncategorized_accounts?limit=10&current_id=294098', headers={'Authorization': 'Token ruor7REQi9KJz6wIQKDXvwtt'})\n",
    "data = x.json()\n",
    "df = pd.DataFrame(data['users'])\n",
    "display(df)\n",
    "dfnew = pd.DataFrame(columns=['id','handle','name','url','gender','country','captions'], data = df[['id','handle','name','url','gender','country','captions']].values)\n",
    "capi = dfnew.loc[0,'captions']\n",
    "print(len(capi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'ali', 'bhatt', 'wikis', 'enabled', 'wiki', 'software', 'otherwise', 'known', 'wiki', 'engines', 'wiki', 'engine', 'form', 'content', 'management', 'system', 'differs', 'web', 'based', 'systems', 'blog', 'software', 'content', 'created', 'without', 'defined', 'owner', 'leader', 'wikis', 'little', 'inherent', 'structure', 'allowing', 'structure', 'emerge', 'according', 'needs', 'users', 'wiki', 'engines', 'usually', 'allow', 'content', 'written', 'using', 'simplified', 'markup', 'language', 'sometimes', 'edited', 'help', 'rich', 'text', 'editor', 'dozens', 'different', 'wiki', 'engines', 'use', 'standalone', 'part', 'software', 'bug', 'tracking', 'systems', 'wiki', 'engines', 'open', 'source', 'whereas', 'others', 'proprietary', 'permit', 'control', 'different', 'functions', 'levels', 'access', 'example', 'editing', 'rights', 'may', 'permit', 'changing', 'adding', 'removing', 'material', 'others', 'may', 'permit', 'access', 'without', 'enforcing', 'access', 'control', 'rules', 'may', 'imposed', 'organize', 'content']\n",
      "Before:  101\n",
      "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1], [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "#Converting to keywords\n",
    "capi = ['hello this is ali bhatt','Wikis are enabled by wiki software, otherwise known as wiki engines. A wiki engine, being a form of a content management system, differs from other web-based systems such as blog software, in that the content is created without any defined owner or leader, and wikis have little inherent structure, allowing structure to emerge according to the needs of the users.[1] Wiki engines usually allow content to be written using a simplified markup language and sometimes edited with the help of a rich-text editor.[2] There are dozens of different wiki engines in use, both standalone and part of other software, such as bug tracking systems. Some wiki engines are open source, whereas others are proprietary. Some permit control over different functions (levels of access); for example, editing rights may permit changing, adding, or removing material. Others may permit access without enforcing access control. Other rules may be imposed to organize content.']\n",
    "captions = process(capi,avoidwords)\n",
    "caption_array = captions[0]\n",
    "print(caption_array)\n",
    "print(\"Before: \",len(caption_array))\n",
    "\n",
    "#Temporary array i-> interim\n",
    "icaption_array = [i for i in caption_array]\n",
    "# Removing words not in dictionary also single characters\n",
    "for x in caption_array:\n",
    "    try:\n",
    "        checkword = w.similarity(x,'something') #Check word if exist in googlenews\n",
    "        if len(x) <2: #Removing single character\n",
    "            icaption_array.pop(icaption_array.index(x))\n",
    "    except KeyError:\n",
    "        icaption_array.pop(icaption_array.index(x))\n",
    "#Restore Array\n",
    "caption_array = [i for i in icaption_array]\n",
    "\n",
    "# Code to get frequency distribution and unique keywords array\n",
    "ar =[]\n",
    "score =[]\n",
    "keywords = []\n",
    "caption_freq = []\n",
    "counts = Counter(caption_array)\n",
    "if len(counts) > 0:\n",
    "    labels, values = zip(*counts.items())\n",
    "    ## sort your values in descending order\n",
    "    indSort = np.argsort(values)[::-1]\n",
    "    ## rearrange your data\n",
    "    keywords = np.array(labels)[indSort]  # Label\n",
    "    caption_freq = np.array(values)[indSort]  # Values\n",
    "\n",
    "else:\n",
    "    raise Exception(\"No captions to profile\")\n",
    "#Google similaity function\n",
    "for x in categories:\n",
    "    empty = []\n",
    "    for y in keywords:\n",
    "        try:\n",
    "            empty.append(w.similarity(x,y))\n",
    "        except:\n",
    "            empty.append(0)\n",
    "    ar.append(empty)\n",
    "\n",
    "### CHANGES  MADE\n",
    "#Normalize | top select\n",
    "for key in range(len(categories)):\n",
    "    ar[key] = normalizeSD(ar[key],3)\n",
    "print(ar)\n",
    "# Multiply with frequency\n",
    "for i in range(len(ar[0])):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "q = pd.DataFrame(columns = ['id','url'], data = [[123,'f.com'],[345,'q.com']])\n",
    "print(q.loc[0,'id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
